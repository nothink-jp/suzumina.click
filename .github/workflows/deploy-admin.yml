name: Deploy Admin App to Cloud Run

on:
  push:
    branches:
      - main
    paths:
      - 'apps/admin/**'
      - 'packages/shared-types/**'
      - 'packages/ui/**'
      - '.github/workflows/deploy-admin.yml'
  
  # Manual triggering
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: asia-northeast1
  SERVICE_NAME: suzumina-admin
  REPOSITORY: suzumina-click-web
  IMAGE_NAME: suzumina-admin

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Enable Corepack
        run: corepack enable
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'
      
      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV
      
      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Build shared types
        run: pnpm --filter @suzumina.click/shared-types build
      
      - name: Build UI components
        run: pnpm --filter @suzumina.click/ui build
      
      - name: Run admin app tests
        run: pnpm --filter @suzumina.click/admin test || echo "No tests configured for admin app"
      
      - name: Run admin app linting
        run: pnpm --filter @suzumina.click/admin lint
      
      - name: Run admin app type checking
        run: pnpm --filter @suzumina.click/admin typecheck
      
      # Google Cloud authentication
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: 'projects/${{ secrets.GCP_PROJECT_NUMBER }}/locations/global/workloadIdentityPools/github-pool/providers/github-provider'
          service_account: 'github-actions-sa@${{ secrets.GCP_PROJECT_ID }}.iam.gserviceaccount.com'
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}
      
      - name: Configure Docker to use gcloud as a credential helper
        run: |
          gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev
      
      # Set up Docker Buildx for advanced caching
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      # Build and push Docker image with cache optimization
      - name: Build and push Docker image (optimized)
        run: |
          # Generate image tag
          IMAGE_TAG="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"
          LATEST_TAG="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.IMAGE_NAME }}:latest"
          CACHE_TAG="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.IMAGE_NAME }}:cache"
          
          # Build with cache optimization
          docker buildx build \
            --platform linux/amd64 \
            --file apps/admin/Dockerfile \
            --tag $IMAGE_TAG \
            --tag $LATEST_TAG \
            --cache-from type=registry,ref=$CACHE_TAG \
            --cache-to type=registry,ref=$CACHE_TAG,mode=max \
            --push \
            .
          
          echo "‚úÖ Admin Docker image built and pushed with optimized caching"
          
          # Immediate cache cleanup after build
          echo "üßπ Cleaning up admin build cache tags..."
          
          # Check if there are multiple cache tags and delete older ones
          CACHE_IMAGES=$(gcloud artifacts docker images list \
            ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.IMAGE_NAME }} \
            --filter="tags:cache" \
            --format="value(IMAGE@DIGEST,createTime)" \
            --sort-by="~createTime" | tail -n +2)
          
          if [ -n "$CACHE_IMAGES" ]; then
            echo "Found old admin cache images to clean up"
            echo "$CACHE_IMAGES" | while IFS=$'\t' read -r digest createTime; do
              if [ -n "$digest" ]; then
                echo "Removing old admin cache image: $digest (created: $createTime)"
                gcloud artifacts docker images delete "$digest" --quiet || echo "Failed to delete $digest"
              fi
            done
          else
            echo "No old admin cache images to clean up"
          fi
          
          # Save image tag for deployment
          echo "IMAGE_TAG=$IMAGE_TAG" >> $GITHUB_ENV
      
      # Deploy to Cloud Run
      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.IMAGE_TAG }} \
            --region ${{ env.REGION }} \
            --platform managed \
            --allow-unauthenticated \
            --service-account="suzumina-admin-sa@${{ env.PROJECT_ID }}.iam.gserviceaccount.com" \
            --set-env-vars="NODE_ENV=production,NEXT_TELEMETRY_DISABLED=1,GCP_PROJECT_ID=${{ env.PROJECT_ID }},NEXTAUTH_URL=https://admin.suzumina.click" \
            --set-secrets="DISCORD_CLIENT_ID=DISCORD_CLIENT_ID:latest,DISCORD_CLIENT_SECRET=DISCORD_CLIENT_SECRET:latest,NEXTAUTH_SECRET=NEXTAUTH_SECRET:latest" \
            --memory 512Mi \
            --cpu 1 \
            --min-instances 0 \
            --max-instances 1 \
            --timeout 300 \
            --port 8080

      # Note: Admin access control is handled by the application's Discord authentication
      # The service is publicly accessible but requires admin-level Discord authentication to use
      
      # Health check (admin authentication required)
      - name: Service deployment verification
        run: |
          # Get service URL
          SERVICE_URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \
            --region ${{ env.REGION }} \
            --format 'value(status.address.url)')
          
          echo "Admin service URL: $SERVICE_URL"
          
          # Wait for deployment to be ready
          echo "Waiting for deployment to be ready..."
          sleep 30
          
          # Basic connectivity check (will show 401/403 due to auth requirements)
          echo "Checking service connectivity (expect 401/403 due to admin auth)..."
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$SERVICE_URL" || echo "000")
          
          if [ "$HTTP_CODE" = "401" ] || [ "$HTTP_CODE" = "403" ]; then
            echo "‚úÖ Service deployed successfully (HTTP $HTTP_CODE - authentication required as expected)"
          elif [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Service deployed successfully (HTTP $HTTP_CODE)"
          else
            echo "‚ö†Ô∏è  Service responded with HTTP $HTTP_CODE"
            echo "This may be normal for admin-only services"
          fi
          
          echo "üéØ Admin service deployed to: $SERVICE_URL"
          echo "üîí Access is restricted to authorized admin users only"
      
      # Cleanup old Docker images and Cloud Run revisions
      - name: Cleanup old images and revisions
        run: |
          echo "üßπ Starting cleanup of old admin Docker images and Cloud Run revisions..."
          
          KEEP_IMAGES=5
          KEEP_REVISIONS=3
          REPOSITORY_PATH="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.IMAGE_NAME }}"
          
          # 1. Cloud Run revision cleanup
          echo "üóÇÔ∏è  Cleaning up admin Cloud Run revisions (keeping latest $KEEP_REVISIONS)..."
          
          # Get all revisions sorted by creation time (newest first)
          REVISIONS=$(gcloud run revisions list \
            --service="${{ env.SERVICE_NAME }}" \
            --region="${{ env.REGION }}" \
            --sort-by="~metadata.creationTimestamp" \
            --format="value(metadata.name)" \
            --limit=20)
          
          if [ -n "$REVISIONS" ]; then
            REVISION_ARRAY=($REVISIONS)
            TOTAL_REVISIONS=${#REVISION_ARRAY[@]}
            echo "Found $TOTAL_REVISIONS admin revisions"
            
            if [ $TOTAL_REVISIONS -gt $KEEP_REVISIONS ]; then
              DELETE_COUNT=$((TOTAL_REVISIONS - KEEP_REVISIONS))
              echo "Deleting $DELETE_COUNT old admin revisions..."
              
              for ((i=KEEP_REVISIONS; i<TOTAL_REVISIONS; i++)); do
                REVISION=${REVISION_ARRAY[$i]}
                echo "  Deleting admin revision: $REVISION"
                
                if gcloud run revisions delete "$REVISION" \
                  --region="${{ env.REGION }}" \
                  --quiet 2>/dev/null; then
                  echo "    ‚úÖ Deleted successfully"
                else
                  echo "    ‚ö†Ô∏è  Failed to delete (may be in use)"
                fi
              done
            else
              echo "‚úÖ Admin revision count is within limit ($TOTAL_REVISIONS revisions)"
            fi
          else
            echo "No admin revisions found"
          fi
          
          # 2. Docker image cleanup
          echo "üê≥ Cleaning up admin Docker images (keeping latest $KEEP_IMAGES)..."
          
          # Get all image digests sorted by creation time (oldest first for deletion)
          IMAGES=$(gcloud artifacts docker images list "$REPOSITORY_PATH" \
            --sort-by="CREATE_TIME" \
            --format="value(IMAGE)" \
            --limit=50 2>/dev/null || echo "")
          
          if [ -n "$IMAGES" ]; then
            IMAGE_ARRAY=($IMAGES)
            TOTAL_IMAGES=${#IMAGE_ARRAY[@]}
            echo "Found $TOTAL_IMAGES admin images"
            
            if [ $TOTAL_IMAGES -gt $KEEP_IMAGES ]; then
              DELETE_COUNT=$((TOTAL_IMAGES - KEEP_IMAGES))
              echo "Deleting $DELETE_COUNT old admin images..."
              
              # Delete from beginning (oldest images) when sorted by CREATE_TIME ascending
              for ((i=0; i<DELETE_COUNT; i++)); do
                IMAGE=${IMAGE_ARRAY[$i]}
                echo "  Deleting admin image: $IMAGE"
                
                if gcloud artifacts docker images delete "$IMAGE" \
                  --delete-tags \
                  --quiet 2>/dev/null; then
                  echo "    ‚úÖ Deleted successfully"
                else
                  echo "    ‚ö†Ô∏è  Failed to delete (may be in use)"
                fi
              done
            else
              echo "‚úÖ Admin image count is within limit ($TOTAL_IMAGES images)"
            fi
          else
            echo "No admin images found"
          fi
          
          # 3. Final status
          echo "üìä Admin cleanup summary:"
          
          # Count remaining images
          REMAINING_IMAGES=$(gcloud artifacts docker images list "$REPOSITORY_PATH" \
            --format="value(IMAGE)" 2>/dev/null | wc -l || echo "0")
          echo "  Admin Docker images: $REMAINING_IMAGES remaining"
          
          # Count remaining revisions
          REMAINING_REVISIONS=$(gcloud run revisions list \
            --service="${{ env.SERVICE_NAME }}" \
            --region="${{ env.REGION }}" \
            --format="value(metadata.name)" | wc -l || echo "0")
          echo "  Admin Cloud Run revisions: $REMAINING_REVISIONS remaining"
          
          echo "üéâ Admin cleanup completed!"