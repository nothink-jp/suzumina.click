name: Deploy Cloud Functions

on:
  push:
    branches:
      - main
    paths:
      - 'apps/functions/**'
      - 'packages/shared-types/**'
      - '.github/workflows/deploy-functions.yml'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build shared-types
        run: pnpm --filter=@suzumina.click/shared-types build

      - name: Build functions
        run: pnpm --filter=@suzumina.click/functions build

      - name: Run tests
        run: NODE_ENV=test pnpm --filter=@suzumina.click/functions test

      - name: Authenticate to GCP
        id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/${{ secrets.GCP_PROJECT_NUMBER }}/locations/global/workloadIdentityPools/github-pool/providers/github-provider'
          service_account: 'cloud-functions-deployer-sa@${{ secrets.GCP_PROJECT_ID }}.iam.gserviceaccount.com'

      - name: Setup Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Create deployment bundle
        run: |
          # ‰∏ÄÊôÇÁöÑ„Å™„Éá„Éó„É≠„Ç§„É°„É≥„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê
          mkdir -p ./deployment-temp
          
          # shared-types„Çí„Éë„ÉÉ„Ç±„Éº„Ç∏Âåñ
          cd packages/shared-types
          pnpm pack --pack-destination ../../deployment-temp
          
          # „Éë„ÉÉ„Ç±„Éº„Ç∏„Éï„Ç°„Ç§„É´Âêç„ÇíÁ¢∫ÂÆü„Å´ÂèñÂæó
          cd ../../deployment-temp
          SHARED_TYPES_FILE=$(ls suzumina.click-shared-types-*.tgz | head -n1)
          echo "Found shared-types package: $SHARED_TYPES_FILE"
          
          # functions„ÅÆ„Éì„É´„ÉâÊàêÊûúÁâ©„Å®package.json„Çí„Ç≥„Éî„Éº
          cp -r ../apps/functions/lib ./
          cp ../apps/functions/package.json ./
          
          # Node.js„Çπ„ÇØ„É™„Éó„Éà„Åßpackage.json„ÇíÂÆâÂÖ®„Å´Â§âÊõ¥
          SHARED_TYPES_FILE="$SHARED_TYPES_FILE" node -e "
            const fs = require('fs');
            const pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));
            
            // workspace‰æùÂ≠òÈñ¢‰øÇ„ÇíÂÆüÈöõ„ÅÆ„Éï„Ç°„Ç§„É´„Éë„Çπ„Å´Â§âÊõ¥
            if (pkg.dependencies && pkg.dependencies['@suzumina.click/shared-types']) {
              pkg.dependencies['@suzumina.click/shared-types'] = 'file:./' + process.env.SHARED_TYPES_FILE;
            }
            
            // ÈñãÁô∫Áî®„Çπ„ÇØ„É™„Éó„Éà„ÇíÂâäÈô§
            if (pkg.scripts) {
              delete pkg.scripts.build;
              delete pkg.scripts['build:watch'];
              delete pkg.scripts.lint;
              delete pkg.scripts.format;
              delete pkg.scripts.check;
              delete pkg.scripts.test;
              delete pkg.scripts['test:watch'];
              delete pkg.scripts['test:coverage'];
            }
            
            // devDependencies„ÇíÂâäÈô§
            delete pkg.devDependencies;
            
            // Cloud Functions v2„Åß„ÅØFunctions Framework„ÅåËá™ÂãïÁöÑ„Å´Ëµ∑Âãï„Åô„Çã„Åü„ÇÅ„ÄÅ
            // start„Çπ„ÇØ„É™„Éó„Éà„ÅØ‰∏çË¶Å„ÄÇmain„Ç®„É≥„Éà„É™„Éº„Éù„Ç§„É≥„Éà„ÅÆ„ÅøË®≠ÂÆö
            pkg.main = 'lib/endpoints/index.js';
            
            // engines„Éï„Ç£„Éº„É´„Éâ„ÇÇÁ¢∫ÂÆü„Å´Ë®≠ÂÆö
            if (!pkg.engines) {
              pkg.engines = {};
            }
            pkg.engines.node = '22';
            
            fs.writeFileSync('package.json', JSON.stringify(pkg, null, 2));
          "
          
          # ‰æùÂ≠òÈñ¢‰øÇ„Çí„Ç§„É≥„Çπ„Éà„Éº„É´ÔºàproductionÁî®Ôºâ
          pnpm install --prod --frozen-lockfile
          
          # „Éá„Éó„É≠„Ç§Áî®„ÅÆzip„Éï„Ç°„Ç§„É´„Çí‰ΩúÊàêÔºàCloud Functions„ÅØzip„ÇíË¶ÅÊ±ÇÔºâ
          zip -r ../functions-deployment.zip *
          cd ..
          
          echo "Deployment bundle created: functions-deployment.zip"

      - name: Upload to Cloud Storage
        run: |
          # „Éá„Éó„É≠„Ç§Áî®„ÅÆCloud Storage„Éê„Ç±„ÉÉ„ÉàÂêç„ÇíË®≠ÂÆö
          BUCKET_NAME="${{ secrets.GCP_PROJECT_ID }}-functions-deployment"
          
          # „Éê„Ç±„ÉÉ„Éà„ÅåÂ≠òÂú®„Åô„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ
          if ! gsutil ls gs://$BUCKET_NAME/ &>/dev/null; then
            echo "‚ùå Error: Deployment bucket does not exist: gs://$BUCKET_NAME"
            echo "Please create the bucket first using one of these methods:"
            echo ""
            echo "1. Using gcloud CLI:"
            echo "   gcloud storage buckets create gs://$BUCKET_NAME --location=asia-northeast1 --project=${{ secrets.GCP_PROJECT_ID }}"
            echo ""
            echo "2. Using Terraform (recommended):"
            echo "   Add the following resource to your terraform configuration:"
            echo "   resource \"google_storage_bucket\" \"functions_deployment\" {"
            echo "     name     = \"$BUCKET_NAME\""
            echo "     location = \"asia-northeast1\""
            echo "   }"
            echo ""
            echo "3. Using Google Cloud Console:"
            echo "   Visit https://console.cloud.google.com/storage and create a bucket named '$BUCKET_NAME'"
            exit 1
          else
            echo "‚úÖ Deployment bucket exists: $BUCKET_NAME"
          fi
          
          # „Ç¢„Éº„Ç´„Ç§„Éñ„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          ARCHIVE_NAME="functions-${TIMESTAMP}.zip"
          
          echo "üì§ Uploading deployment archive..."
          gsutil cp functions-deployment.zip gs://$BUCKET_NAME/$ARCHIVE_NAME
          echo "‚úÖ Uploaded: gs://$BUCKET_NAME/$ARCHIVE_NAME"
          
          # Áí∞Â¢ÉÂ§âÊï∞„Å®„Åó„Å¶‰øùÂ≠ò
          echo "DEPLOYMENT_SOURCE=gs://$BUCKET_NAME/$ARCHIVE_NAME" >> $GITHUB_ENV
          echo "BUCKET_NAME=$BUCKET_NAME" >> $GITHUB_ENV

      - name: Check and wait for pending operations
        run: |
          echo "üîç Checking for pending Cloud Functions operations..."
          
          # ÈÄ≤Ë°å‰∏≠„ÅÆ„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„Çí„ÉÅ„Çß„ÉÉ„ÇØ
          PENDING_OPS=$(gcloud functions operations list \
            --region=asia-northeast1 \
            --project=${{ secrets.GCP_PROJECT_ID }} \
            --filter="done=false" \
            --format="value(name)" || echo "")
          
          if [ ! -z "$PENDING_OPS" ]; then
            echo "‚è≥ Found pending operations, waiting for completion..."
            echo "$PENDING_OPS"
            
            # ÊúÄÂ§ß5ÂàÜÈñìÂæÖÊ©ü
            for i in {1..30}; do
              sleep 10
              PENDING_OPS=$(gcloud functions operations list \
                --region=asia-northeast1 \
                --project=${{ secrets.GCP_PROJECT_ID }} \
                --filter="done=false" \
                --format="value(name)" || echo "")
              
              if [ -z "$PENDING_OPS" ]; then
                echo "‚úÖ All pending operations completed"
                break
              fi
              
              echo "Still waiting... ($i/30)"
              
              if [ $i -eq 30 ]; then
                echo "‚ö†Ô∏è Warning: Some operations are still pending after 5 minutes"
                echo "Continuing with deployment..."
              fi
            done
          else
            echo "‚úÖ No pending operations found"
          fi

      - name: Deploy fetchYouTubeVideos function
        run: |
          echo "üöÄ Deploying fetchYouTubeVideos function..."
          
          # „É™„Éà„É©„Ç§„É≠„Ç∏„ÉÉ„ÇØ‰ªò„Åç„Åß„Éá„Éó„É≠„Ç§
          for attempt in 1 2 3; do
            echo "Attempt $attempt/3..."
            
            if gcloud functions deploy fetchYouTubeVideos \
              --source ${{ env.DEPLOYMENT_SOURCE }} \
              --runtime nodejs22 \
              --entry-point fetchYouTubeVideos \
              --trigger-topic youtube-video-fetch-trigger \
              --region asia-northeast1 \
              --project ${{ secrets.GCP_PROJECT_ID }} \
              --set-env-vars NODE_ENV=production,FUNCTION_SIGNATURE_TYPE=cloudevent,FUNCTION_TARGET=fetchYouTubeVideos,ENABLE_ENTITY_V2=true \
              --memory 512MB \
              --timeout 540s \
              --max-instances 10 \
              --quiet; then
              echo "‚úÖ fetchYouTubeVideos deployed successfully"
              break
            else
              echo "‚ùå Deploy failed on attempt $attempt"
              if [ $attempt -eq 3 ]; then
                echo "üö® All retry attempts failed"
                exit 1
              fi
              echo "‚è≥ Waiting 30 seconds before retry..."
              sleep 30
            fi
          done


      - name: Deploy fetchDLsiteWorksIndividualAPI function
        run: |
          echo "üöÄ Deploying fetchDLsiteWorksIndividualAPI function..."
          
          # „É™„Éà„É©„Ç§„É≠„Ç∏„ÉÉ„ÇØ‰ªò„Åç„Åß„Éá„Éó„É≠„Ç§
          for attempt in 1 2 3; do
            echo "Attempt $attempt/3..."
            
            if gcloud functions deploy fetchDLsiteWorksIndividualAPI \
              --source ${{ env.DEPLOYMENT_SOURCE }} \
              --runtime nodejs22 \
              --entry-point fetchDLsiteWorksIndividualAPI \
              --trigger-topic dlsite-individual-api-trigger \
              --region asia-northeast1 \
              --project ${{ secrets.GCP_PROJECT_ID }} \
              --set-env-vars NODE_ENV=production,FUNCTION_SIGNATURE_TYPE=cloudevent,FUNCTION_TARGET=fetchDLsiteWorksIndividualAPI,INDIVIDUAL_INFO_API_ENABLED=true,API_ONLY_MODE=true,MAX_CONCURRENT_API_REQUESTS=5,API_REQUEST_DELAY_MS=500,ENABLE_DATA_VALIDATION=true,MINIMUM_QUALITY_SCORE=80,ENABLE_TIMESERIES_INTEGRATION=true,LOG_LEVEL=info,ENABLE_ENTITY_V2=true \
              --memory 2Gi \
              --timeout 540s \
              --max-instances 2 \
              --quiet; then
              echo "‚úÖ fetchDLsiteWorksIndividualAPI deployed successfully"
              break
            else
              echo "‚ùå Deploy failed on attempt $attempt"
              if [ $attempt -eq 3 ]; then
                echo "üö® All retry attempts failed"
                exit 1
              fi
              echo "‚è≥ Waiting 30 seconds before retry..."
              sleep 30
            fi
          done

# collectDLsiteTimeseries „Éá„Éó„É≠„Ç§„ÅØÁµ±Âêà„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Å´„Çà„ÇäÂªÉÊ≠¢
# fetchDLsiteWorksIndividualAPI „ÅåÊôÇÁ≥ªÂàó„Éá„Éº„ÇøÂèéÈõÜÊ©üËÉΩ„ÇíÁµ±ÂêàÂÆüË°å

      - name: Cleanup deployment artifacts
        if: always()
        run: |
          # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„ÇíÂâäÈô§
          rm -rf ./deployment-temp
          rm -f functions-deployment.zip
          
          # Âè§„ÅÑ„Éá„Éó„É≠„Ç§„É°„É≥„Éà„Éï„Ç°„Ç§„É´„ÇíÂâäÈô§ÔºàÊúÄÊñ∞5ÂÄã„Çí‰øùÊåÅÔºâ
          if [ ! -z "${{ env.BUCKET_NAME }}" ]; then
            echo "Cleaning up old deployment files..."
            gsutil ls gs://${{ env.BUCKET_NAME }}/functions-*.zip | \
              sort -r | \
              tail -n +6 | \
              xargs -r gsutil rm || echo "No old files to clean up"
          fi

      - name: Deploy status summary
        run: |
          echo "## üöÄ „Éá„Éó„É≠„Ç§ÁµêÊûú" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üì¶ „Éá„Éó„É≠„Ç§„Åï„Çå„ÅüÈñ¢Êï∞" >> $GITHUB_STEP_SUMMARY
          echo "- **fetchYouTubeVideos**: ‚úÖ „Éá„Éó„É≠„Ç§ÂÆå‰∫Ü („É™„Éà„É©„Ç§„É≠„Ç∏„ÉÉ„ÇØ‰ªò„Åç)" >> $GITHUB_STEP_SUMMARY
          echo "  - „Éà„É™„Ç¨„Éº: \`youtube-video-fetch-trigger\` (Pub/Sub)" >> $GITHUB_STEP_SUMMARY
          echo "- **fetchDLsiteWorksIndividualAPI**: ‚úÖ „Éá„Éó„É≠„Ç§ÂÆå‰∫Ü (Áµ±Âêà„Éá„Éº„ÇøÂèéÈõÜ„Éª100% API-Only)" >> $GITHUB_STEP_SUMMARY
          echo "  - „Éà„É™„Ç¨„Éº: \`dlsite-individual-api-trigger\` (Pub/Sub)" >> $GITHUB_STEP_SUMMARY
          echo "  - Ê©üËÉΩ: Âü∫Êú¨„Éá„Éº„ÇøÊõ¥Êñ∞ + ÊôÇÁ≥ªÂàó„Éá„Éº„ÇøÂèéÈõÜ„ÅÆÁµ±ÂêàÂÆüË°å" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîß Ë®≠ÂÆöÊÉÖÂ†±" >> $GITHUB_STEP_SUMMARY
          echo "- **„Éó„É≠„Ç∏„Çß„ÇØ„Éà**: \`${{ secrets.GCP_PROJECT_ID }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **„É™„Éº„Ç∏„Éß„É≥**: \`asia-northeast1\`" >> $GITHUB_STEP_SUMMARY
          echo "- **„É©„É≥„Çø„Ç§„É†**: \`nodejs22\`" >> $GITHUB_STEP_SUMMARY
          echo "- **„É°„É¢„É™**: \`512MB\`" >> $GITHUB_STEP_SUMMARY
          echo "- **„Çø„Ç§„É†„Ç¢„Ç¶„Éà**: \`540Áßí\`" >> $GITHUB_STEP_SUMMARY
          echo "- **„Éá„Éó„É≠„Ç§„ÇΩ„Éº„Çπ**: \`${{ env.DEPLOYMENT_SOURCE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üõ°Ô∏è ÊîπÂñÑÁÇπ" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ „Éá„Éó„É≠„Ç§Ââç„Å´„Éö„É≥„Éá„Ç£„É≥„Ç∞‰∏≠„ÅÆ„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„Çí„ÉÅ„Çß„ÉÉ„ÇØ" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ 3Âõû„ÅÆ„É™„Éà„É©„Ç§„É≠„Ç∏„ÉÉ„ÇØ„Åß‰ø°È†ºÊÄßÂêë‰∏ä" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Èñ¢Êï∞„Éá„Éó„É≠„Ç§„ÇíÈ†ÜÊ¨°ÂÆüË°å„Åó„Å¶Á´∂Âêà„ÇíÂõûÈÅø" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Âè§„ÅÑ„É™„Éì„Ç∏„Éß„É≥„ÅÆËá™Âãï„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÔºàÊúÄÊñ∞5ÂÄã„Çí‰øùÊåÅÔºâ" >> $GITHUB_STEP_SUMMARY

      # Cleanup old Cloud Functions revisions
      - name: Cleanup old Cloud Functions revisions
        run: |
          echo "üßπ Cleaning up old Cloud Functions revisions (keeping last 5 versions)"
          
          # Function names (Áµ±Âêà„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Å´„Çà„Çä2Èñ¢Êï∞„ÅÆ„Åø)
          FUNCTIONS=("fetchyoutubevideos" "fetchdlsiteworksindividualapi")
          KEEP_COUNT=5
          
          for function_name in "${FUNCTIONS[@]}"; do
            echo "Processing function: $function_name"
            
            # Get revisions sorted by creation time (newest first)
            revisions=$(gcloud run revisions list \
              --service="$function_name" \
              --region="asia-northeast1" \
              --project="${{ secrets.GCP_PROJECT_ID }}" \
              --sort-by="~metadata.creationTimestamp" \
              --format="value(metadata.name)" \
              --limit=20)
            
            if [ -z "$revisions" ]; then
              echo "No revisions found for $function_name"
              continue
            fi
            
            # Convert to array
            revision_array=($revisions)
            total_count=${#revision_array[@]}
            
            echo "Total revisions for $function_name: $total_count"
            
            if [ $total_count -le $KEEP_COUNT ]; then
              echo "Revision count is within keep limit, skipping cleanup"
              continue
            fi
            
            # Delete old revisions
            deleted=0
            for ((i=KEEP_COUNT; i<total_count; i++)); do
              revision=${revision_array[$i]}
              echo "Deleting revision: $revision"
              
              if gcloud run revisions delete "$revision" \
                --region="asia-northeast1" \
                --project="${{ secrets.GCP_PROJECT_ID }}" \
                --quiet; then
                deleted=$((deleted + 1))
              else
                echo "Failed to delete $revision, but continuing..."
              fi
            done
            
            echo "‚úÖ Deleted $deleted revisions for $function_name"
          done || true  # Don't fail the entire workflow if cleanup fails